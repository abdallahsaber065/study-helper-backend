{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc42bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the first image\n",
    "video_file_path = (\n",
    "    \"F:\\PC Data\\Pictures\\WhatsApp Image 2025-02-14 at 02.36.37_1925f510.jpg\"\n",
    ")\n",
    "uploaded_image = client.files.upload(file=video_file_path)\n",
    "\n",
    "\n",
    "# Create the prompt with text and multiple images\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\n",
    "        \"Explain the contents of the uploaded image.\",\n",
    "        uploaded_image,  # Use the uploaded file reference\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "print(uploaded_image.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6794ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv.load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    reasoning_effort=\"low\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Explain the contents of the uploaded image.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"{uploaded_image.uri}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d741405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import time\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Upload the first image\n",
    "video_file_path = (\n",
    "    \"F:\\PC Data\\Pictures\\Snapsave.app_-bGw1Xj9o0w7cQHU7yZDWdpeHxCBxvPYIM.mp4\"\n",
    ")\n",
    "uploaded_video = client.files.upload(file=video_file_path)\n",
    "time.sleep(5)  # Wait for the upload to complete\n",
    "\n",
    "# Create the prompt with text and multiple images\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[\n",
    "        \"Explain the contents of the uploaded video.\",\n",
    "        uploaded_video,  # Use the uploaded file reference\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "print(uploaded_video.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd441df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv.load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    reasoning_effort=\"low\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Explain the contents of the uploaded video.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"{uploaded_video.uri}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f756b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "import time\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "start_upload = time.time()\n",
    "# Upload the first pdf\n",
    "pdf_file_path = \"F:\\\\Collage\\\\Machine Learning\\\\Lectures\\\\9-Neural Network.pdf\"\n",
    "uploaded_pdf = client.files.upload(file=pdf_file_path)\n",
    "end_upload = time.time()\n",
    "print(f\"PDF upload took {end_upload - start_upload} seconds\")\n",
    "\n",
    "start_generate = time.time()\n",
    "# Create the prompt with text and multiple images\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    contents=[\n",
    "        \"Explain the contents of the uploaded pdf.\",\n",
    "        uploaded_pdf,  # Use the uploaded file reference\n",
    "    ],\n",
    ")\n",
    "\n",
    "end_generate = time.time()\n",
    "print(f\"Content generation took {end_generate - start_generate} seconds\")\n",
    "\n",
    "print(response.text)\n",
    "print(uploaded_pdf.uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd4b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "dotenv.load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    reasoning_effort=\"low\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Explain the contents of the uploaded pdf.\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"{uploaded_pdf.uri}\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fbebb3",
   "metadata": {},
   "source": [
    "# Here is Gemini implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files stored locally\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "file_path = \"F:\\\\Collage\\\\Machine Learning\\\\Lectures\\\\6-Naive Bayes.pdf\"\n",
    "\n",
    "\n",
    "# Upload the PDF using the File API\n",
    "sample_file = client.files.upload(\n",
    "    file=file_path,\n",
    ")\n",
    "\n",
    "prompt = \"Summarize this document\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=[sample_file, \"Summarize this document\"]\n",
    ")\n",
    "print(response.text)\n",
    "# You can verify the API successfully stored the uploaded file and get its metadata by calling files.get. Only the name (and by extension, the uri) are unique.\n",
    "\n",
    "file = client.files.upload(\n",
    "    file=\"F:\\\\Collage\\\\Machine Learning\\\\Lectures\\\\6-Naive Bayes.pdf\",\n",
    "    config=dict(\n",
    "        mime_type=\"application/pdf\",\n",
    "        display_name=\"Naive Bayes Lecture Notes\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "file_info = client.files.get(name=file.name)\n",
    "print(file_info)\n",
    "# Output: name='files/cc0ggzzy3pss' display_name='Naive Bayes Lecture Notes' mime_type='application/pdf' size_bytes=244052 create_time=datetime.datetime(2025, 5, 29, 4, 40, 2, 209354, tzinfo=TzInfo(UTC)) expiration_time=datetime.datetime(2025, 5, 31, 4, 40, 1, 751085, tzinfo=TzInfo(UTC)) update_time=datetime.datetime(2025, 5, 29, 4, 40, 2, 209354, tzinfo=TzInfo(UTC)) sha256_hash='OTgyZjQyOTNhYzVhZDg3ZDY5MDhhYTVhNzI0YjFhMzU0MDBhMTJmMWE2N2M3YTZhYjMxMTYyZmMwZDhmMjk4Zg==' uri='https://generativelanguage.googleapis.com/v1beta/files/cc0ggzzy3pss' download_uri=None state=<FileState.ACTIVE: 'ACTIVE'> source=<FileSource.UPLOADED: 'UPLOADED'> video_metadata=None error=None\n",
    "# cache uri and access is available for 2 days after upload and restricted to the user that uploaded the file (e.g. you cannot access the file using a different API key).\n",
    "# You can use the file's uri to access the file directly, or you can use the file's name to reference it in files.get requests.\n",
    "\n",
    "# Multiple PDFs\n",
    "# The Gemini API is capable of processing multiple PDF documents in a single request, as long as the combined size of the documents and the text prompt stays within the model's context window.\n",
    "\n",
    "doc_path_1 = \"../../examples/data/A17.pdf\"\n",
    "doc_path_2 = \"../../examples/data/A18.pdf\"\n",
    "\n",
    "sample_pdf_1 = client.files.upload(\n",
    "    file=doc_path_1, config=dict(mime_type=\"application/pdf\", display_name=\"A17 Paper\")\n",
    ")\n",
    "sample_pdf_2 = client.files.upload(\n",
    "    file=doc_path_2, config=dict(mime_type=\"application/pdf\", display_name=\"A18 Paper\")\n",
    ")\n",
    "\n",
    "prompt = \"What is the difference between each of the main benchmarks between these two papers? Output these in a table.\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=[sample_pdf_1, sample_pdf_2, prompt]\n",
    ")\n",
    "print(response.text)\n",
    "\n",
    "# Technical details\n",
    "# Gemini supports a maximum of 1,000 document pages. Document pages must be in one of the following text data MIME types:\n",
    "\n",
    "# PDF - application/pdf\n",
    "# JavaScript - application/x-javascript, text/javascript\n",
    "# Python - application/x-python, text/x-python\n",
    "# TXT - text/plain\n",
    "# HTML - text/html\n",
    "# CSS - text/css\n",
    "# Markdown - text/md\n",
    "# CSV - text/csv\n",
    "# XML - text/xml\n",
    "# RTF - text/rtf\n",
    "# For best results place the text prompt after the document contents.\n",
    "# Image support\n",
    "\n",
    "my_file = client.files.upload(file=\"path/to/sample.jpg\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=[my_file, \"Caption this image.\"],\n",
    ")\n",
    "\n",
    "# Supported image formats\n",
    "# Gemini supports the following image format MIME types:\n",
    "\n",
    "# PNG - image/png\n",
    "# JPEG - image/jpeg\n",
    "# WEBP - image/webp\n",
    "# HEIC - image/heic\n",
    "# HEIF - image/heif\n",
    "# For best results place the text prompt after the image contents.\n",
    "# Audio support\n",
    "\n",
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"GOOGLE_API_KEY\")\n",
    "\n",
    "myfile = client.files.upload(file=\"path/to/sample.mp3\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", contents=[\"Describe this audio clip\", myfile]\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "# (plain text without timestamps[compact text])\n",
    "prompt = \"Generate a transcript of the speech.\"\n",
    "\n",
    "print(response.text)\n",
    "\n",
    "# Refer to timestamps\n",
    "# You can refer to specific sections of an audio file using timestamps of the form MM:SS. For example, the following prompt requests a transcript that\n",
    "\n",
    "# Starts at 2 minutes 30 seconds from the beginning of the file.\n",
    "# Ends at 3 minutes 29 seconds from the beginning of the file.\n",
    "\n",
    "# Create a prompt containing timestamps.\n",
    "prompt = \"Provide a transcript of the speech from 02:30 to 03:29.\"\n",
    "\n",
    "# Supported audio formats\n",
    "# Gemini supports the following audio format MIME types:\n",
    "\n",
    "# WAV - audio/wav\n",
    "# MP3 - audio/mp3\n",
    "# AIFF - audio/aiff\n",
    "# AAC - audio/aac\n",
    "# OGG Vorbis - audio/ogg\n",
    "# FLAC - audio/flac\n",
    "# Technical details about audio\n",
    "# Gemini represents each second of audio as 32 tokens; for example, one minute of audio is represented as 1,920 tokens.\n",
    "# Gemini can \"understand\" non-speech components, such as birdsong or sirens.\n",
    "# The maximum supported length of audio data in a single prompt is 9.5 hours. Gemini doesn't limit the number of audio files in a single prompt; however, the total combined length of all audio files in a single prompt can't exceed 9.5 hours.\n",
    "# Gemini downsamples audio files to a 16 Kbps data resolution.\n",
    "# If the audio source contains multiple channels, Gemini combines those channels into a single channel.\n",
    "# GenerateContentConfig supports system instructions and output formats\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client(api_key=\"GEMINI_API_KEY\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"You are a cat. Your name is Neko.\"\n",
    "    ),\n",
    "    contents=\"Hello there\",\n",
    ")\n",
    "# Files stored locally\n",
    "\n",
    "import enum\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict  # Removed Optional\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "\n",
    "class Options(BaseModel):\n",
    "    A: str\n",
    "    B: str\n",
    "    C: str\n",
    "    D: str\n",
    "\n",
    "\n",
    "class Answer(enum.Enum):\n",
    "    A = \"A\"\n",
    "    B = \"B\"\n",
    "    C = \"C\"\n",
    "    D = \"D\"\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "    question: str = Field(..., description=\"The question text (10-30 words)\")\n",
    "    options: Options = Field(..., description=\"Answer options A through D\")\n",
    "    correct_answer: Answer = Field(\n",
    "        ..., description=\"The correct answer (A, B, C, or D)\"\n",
    "    )\n",
    "    explanation: str = Field(\n",
    "        ..., description=\"Explanation for the correct answer (10-30 words)\"\n",
    "    )\n",
    "    hint: str = Field(..., description=\"Hint for the question\")  # Changed\n",
    "    difficulty: str = Field(\n",
    "        ..., description=\"Difficulty level (Easy, Medium, Hard)\"  # Changed\n",
    "    )\n",
    "    category: str = Field(..., description=\"Topic/category of the question\")  # Changed\n",
    "\n",
    "\n",
    "class MCQSet(BaseModel):\n",
    "    title: str = Field(\n",
    "        ..., description=\"The title for this set of MCQs (5-8 words maximum)\"\n",
    "    )\n",
    "    description: str = Field(..., description=\"Description of the MCQ set\")  # Changed\n",
    "    questions: List[Question]\n",
    "    tags: List[str] = Field(\n",
    "        ..., description=\"Tags for categorizing the quiz\"  # Changed\n",
    "    )\n",
    "    difficulty_level: str = Field(\n",
    "        ...,\n",
    "        description=\"Overall difficulty of the quiz (Easy, Medium, Hard)\",  # Changed\n",
    "    )\n",
    "\n",
    "\n",
    "class MCQResponse(BaseModel):\n",
    "    mcq_set: MCQSet\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Generate a set of 5 multiple choice questions (MCQs) about the solar system. Each question should have 4 options (A, B, C, D) and the correct answer. Include an explanation for the correct answer and hints.... fill the model. The questions should be suitable for high school students.\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=\"You are an expert quiz creator. Generate high-quality multiple choice questions (MCQs) with clear options and explanations.\",\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=MCQResponse.model_json_schema(\n",
    "            by_alias=True,  # Use field aliases in the schema\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "print(response.text)\n",
    "\n",
    "# Note: Pydantic validators are not yet supported. If a pydantic.ValidationError occurs, it is suppressed, and .parsed may be empty/null.\n",
    "# for higher quality response, configure a schema on the model, and don't duplicate the schema in the text prompt but rather refer to the schema in the text prompt to add context and instructions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
